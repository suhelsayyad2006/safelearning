{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pretty_print_review_and_label(i):\n",
    "    print(labels[i] + \"\\t:\\t\" + reviews[i][:80] + \"...\")\n",
    "\n",
    "g = open('reviews.txt','r') # Inputs\n",
    "reviews = list(map(lambda x:x[:-1],g.readlines()))\n",
    "g.close()\n",
    "\n",
    "g = open('labels.txt','r') # Target Outputs\n",
    "labels = list(map(lambda x:x[:-1].upper(),g.readlines()))\n",
    "g.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "positive_counts = Counter()\n",
    "negative_counts = Counter()\n",
    "total_counts = Counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(reviews)):\n",
    "    if(labels[i] == 'POSITIVE'):\n",
    "        for word in reviews[i].split(\" \"):\n",
    "            positive_counts[word] += 1\n",
    "            total_counts[word] += 1\n",
    "    else:\n",
    "        for word in reviews[i].split(\" \"):\n",
    "            negative_counts[word] += 1\n",
    "            total_counts[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos_neg_ratios = Counter()\n",
    "\n",
    "for term,cnt in list(total_counts.most_common()):\n",
    "    if(cnt > 100):\n",
    "        pos_neg_ratio = positive_counts[term] / float(negative_counts[term]+1)\n",
    "        pos_neg_ratios[term] = pos_neg_ratio\n",
    "\n",
    "for word,ratio in pos_neg_ratios.most_common():\n",
    "    if(ratio > 1):\n",
    "        pos_neg_ratios[word] = np.log(ratio)\n",
    "    else:\n",
    "        pos_neg_ratios[word] = -np.log((1 / (ratio+0.01)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74074\n"
     ]
    }
   ],
   "source": [
    "vocab = set(total_counts.keys())\n",
    "vocab_size = len(vocab)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "layer_0 = np.zeros((1,vocab_size))\n",
    "layer_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word2index = {}\n",
    "\n",
    "for i,word in enumerate(vocab):\n",
    "    word2index[word] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_target_for_label(label):\n",
    "    if(label == 'POSITIVE'):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_input_layer(review):\n",
    "    \n",
    "    global layer_0\n",
    "    \n",
    "    # clear out previous state, reset the layer to be all 0s\n",
    "    layer_0 *= 0\n",
    "    for word in review.split(\" \"):\n",
    "        layer_0[0][word2index[word]] += 1\n",
    "\n",
    "update_input_layer(reviews[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "review_counter = Counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for word in reviews[0].split(\" \"):\n",
    "    review_counter[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def keySwitch(M,c,l):\n",
    "    c_star = getBitVector(c,l)\n",
    "    return M.dot(c_star)\n",
    "\n",
    "def getRandomMatrix(row,col,bound):\n",
    "    A = np.zeros((row,col))\n",
    "    for i in range(row):\n",
    "        for j in range(col):\n",
    "            A[i][j] = np.random.randint(bound)\n",
    "    return A\n",
    "\n",
    "def getBitMatrix(S,l):\n",
    "    S_star = list()\n",
    "    for i in range(l):\n",
    "        S_star.append(S*2**(l-i-1))\n",
    "    S_star = np.array(S_star).transpose(1,2,0).reshape(len(S),len(S[0])*l)\n",
    "    return S_star\n",
    "\n",
    "def getSecretKey(T):\n",
    "    assert(T.ndim == 2)\n",
    "    I = np.eye(len(T)) # num rows\n",
    "    return hCat(I,T)\n",
    "\n",
    "def hCat(A,B):\n",
    "    return np.concatenate((A,B),1)\n",
    "\n",
    "def vCat(A,B):\n",
    "    return np.concatenate((A,B),0)\n",
    "\n",
    "def keySwitchMatrix(S, T,l):\n",
    "    S_star = getBitMatrix(S,l)\n",
    "    A = getRandomMatrix(T.shape[1],S_star.shape[1], aBound)\n",
    "    E = getRandomMatrix(S_star.shape[0], S_star.shape[1], eBound)\n",
    "    return vCat(S_star + E - T.dot(A), A)\n",
    "\n",
    "def encrypt(T, x,w,l):\n",
    "    return keySwitch(keySwitchMatrix(np.eye(len(x)),T,l), w * x,l)\n",
    "\n",
    "def addVectors(c1, c2):\n",
    "    return c1 + c2\n",
    "\n",
    "def linearTransform(M, c, l):\n",
    "    return M.dot(getBitVector(c, l)).astype('int64')\n",
    "\n",
    "def linearTransformClient(G, S, T, l):\n",
    "    return keySwitchMatrix(G.dot(S), T,l)\n",
    "\n",
    "def vectorize(M):\n",
    "    ans = np.zeros((len(M) * len(M[0]),1))\n",
    "    for i in range(len(M)):\n",
    "        for j in range(len(M[0])):\n",
    "            ans[i * len(M[0]) + j][0] = M[i][j]\n",
    "    return ans\n",
    "\n",
    "def decrypt(S, c,w):\n",
    "    Sc = S.dot(c)\n",
    "    return (Sc / w).astype('float').round().astype('int64')\n",
    "\n",
    "def innerProdClient(T,l):\n",
    "    S = getSecretKey(T)\n",
    "    tvsts = vectorize(S.T.dot(S)).T\n",
    "    mvsts = copyRows(tvsts, len(T))\n",
    "    return keySwitchMatrix(mvsts,T,l)\n",
    "\n",
    "def copyRows(row, numrows):\n",
    "    ans = np.zeros((numrows, len(row[0])))\n",
    "    for i in range(len(ans)):\n",
    "        for j in range(len(ans[0])):\n",
    "            ans[i][j] = row[0][j]\n",
    "            \n",
    "    return ans\n",
    "\n",
    "def innerProd(c1, c2, M,l):\n",
    "    \n",
    "    cc1 = np.zeros((len(c1),1))\n",
    "    for i in range(len(c1)):\n",
    "        cc1[i][0] = c1[i]\n",
    "    \n",
    "    cc2 = np.zeros((1, len(c2)))\n",
    "    for i in range(len(c2)):\n",
    "        cc2[0][i] = c2[i]\n",
    "        \n",
    "    cc = vectorize(cc1.dot(cc2))\n",
    "    \n",
    "    bv = getBitVector((cc / w).round().astype('int64'),l)\n",
    "    \n",
    "    return M.dot(bv)\n",
    "\n",
    "def one_way_encrypt_vector(vector,scaling_factor = 1000):\n",
    "    padded_vector = np.random.rand(len(vector)+1)\n",
    "    padded_vector[0:len(vector)] = vector\n",
    "    \n",
    "    vec_len = len(padded_vector)\n",
    "    \n",
    "    M_temp = (M_keys[vec_len-2].T*padded_vector*scaling_factor / (vec_len-1)).T\n",
    "    e_vector = innerProd(c_ones[vec_len-2],c_ones[vec_len-2],M_temp,l)\n",
    "    return e_vector.astype('int64')\n",
    "\n",
    "def load_linear_transformation(syn0_text,scaling_factor = 1000):\n",
    "    syn0_text *= scaling_factor\n",
    "    return linearTransformClient(syn0_text.T,getSecretKey(T),T,l)\n",
    "\n",
    "def s_decrypt(vec):\n",
    "    return decrypt(getSecretKey(T_keys[len(vec)-2]),vec,w)\n",
    "\n",
    "def add_vectors(x,y,scaling_factor = 1000):\n",
    "    return x + y\n",
    "\n",
    "def transpose(syn1):\n",
    "\n",
    "    rows = len(syn1)\n",
    "    cols = len(syn1[0]) - 1\n",
    "    \n",
    "    max_rc = max(rows,cols)\n",
    "    \n",
    "    syn1_c = list()\n",
    "    for i in range(len(syn1)):\n",
    "        tmp = np.zeros(max_rc+1)\n",
    "        tmp[:len(syn1[i])] = syn1[i]\n",
    "        syn1_c.append(tmp)\n",
    "    \n",
    "    syn1_c_transposed = list()\n",
    "    \n",
    "    for row_i in range(cols):\n",
    "        syn1t_column = innerProd(syn1_c[0],v_onehot[max_rc-1][row_i],M_onehot[max_rc-1][0],l) / scaling_factor\n",
    "        for col_i in range(rows-1):\n",
    "            syn1t_column += innerProd(syn1_c[col_i+1],v_onehot[max_rc-1][row_i],M_onehot[max_rc-1][col_i+1],l) / scaling_factor\n",
    "\n",
    "        syn1_c_transposed.append(syn1t_column[0:rows+1])\n",
    "    \n",
    "    return syn1_c_transposed\n",
    "\n",
    "def int2bin(x):\n",
    "    s = list()\n",
    "    mod = 2\n",
    "    while(x > 0):\n",
    "        s.append(int(x % 2))\n",
    "        x = int(x / 2)\n",
    "    return np.array(list(reversed(s))).astype('int64')\n",
    "\n",
    "\n",
    "def getBitVector(c,l):\n",
    "    m = len(c)\n",
    "    c_star = np.zeros(l * m,dtype='int64')\n",
    "    for i in range(m):\n",
    "        local_c = int(c[i])\n",
    "        if(local_c < 0):\n",
    "            local_c = -local_c\n",
    "        b = int2bin(local_c)\n",
    "        if(c[i] < 0):\n",
    "            b *= -1\n",
    "        if(c[i] == 0):\n",
    "            b *= 0\n",
    "#         try:\n",
    "        c_star[(i * l) + (l-len(b)): (i+1) * l] += b\n",
    "#         except:\n",
    "#             print(len(b))\n",
    "#             print(i)\n",
    "#             print(len(c_star[(i * l) + (l-len(b)): (i+1) * l]))\n",
    "    return c_star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l = 100\n",
    "w = 2 ** 25\n",
    "\n",
    "aBound = 10\n",
    "tBound = 10\n",
    "eBound = 10\n",
    "\n",
    "max_dim = 16\n",
    "\n",
    "scaling_factor = 1000\n",
    "\n",
    "# keys\n",
    "T_keys = list()\n",
    "for i in range(max_dim):\n",
    "    T_keys.append(np.random.rand(i+1,1))\n",
    "\n",
    "# one way encryption transformation\n",
    "M_keys = list()\n",
    "for i in range(max_dim):\n",
    "    M_keys.append(innerProdClient(T_keys[i],l))\n",
    "\n",
    "M_onehot = list()\n",
    "for h in range(max_dim):\n",
    "    i = h+1\n",
    "    buffered_eyes = list()\n",
    "    for row in np.eye(i+1):\n",
    "        buffer = np.ones(i+1)\n",
    "        buffer[0:i+1] = row\n",
    "        buffered_eyes.append((M_keys[i-1].T * buffer).T)\n",
    "    M_onehot.append(buffered_eyes)\n",
    "    \n",
    "c_ones = list()\n",
    "for i in range(max_dim):\n",
    "    c_ones.append(encrypt(T_keys[i],np.ones(i+1), w, l).astype('int64'))\n",
    "    \n",
    "v_onehot = list()\n",
    "onehot = list()\n",
    "for i in range(max_dim):\n",
    "    eyes = list()\n",
    "    eyes_txt = list()\n",
    "    for eye in np.eye(i+1):\n",
    "        eyes_txt.append(eye)\n",
    "        eyes.append(one_way_encrypt_vector(eye,scaling_factor))\n",
    "    v_onehot.append(eyes)\n",
    "    onehot.append(eyes_txt)\n",
    "\n",
    "H_sigmoid_txt = np.zeros((5,5))\n",
    "\n",
    "H_sigmoid_txt[0][0] = 0.5\n",
    "H_sigmoid_txt[0][1] = 0.25\n",
    "H_sigmoid_txt[0][2] = -1/48.0\n",
    "H_sigmoid_txt[0][3] = 1/480.0\n",
    "H_sigmoid_txt[0][4] = -17/80640.0\n",
    "\n",
    "H_sigmoid = list()\n",
    "for row in H_sigmoid_txt:\n",
    "    H_sigmoid.append(one_way_encrypt_vector(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(layer_2_c):\n",
    "    out_rows = list()\n",
    "    for position in range(len(layer_2_c)-1):\n",
    "\n",
    "        M_position = M_onehot[len(layer_2_c)-2][0]\n",
    "\n",
    "        layer_2_index_c = innerProd(layer_2_c,v_onehot[len(layer_2_c)-2][position],M_position,l) / scaling_factor\n",
    "\n",
    "        x = layer_2_index_c\n",
    "        x2 = innerProd(x,x,M_position,l) / scaling_factor\n",
    "        x3 = innerProd(x,x2,M_position,l) / scaling_factor\n",
    "        x5 = innerProd(x3,x2,M_position,l) / scaling_factor\n",
    "        x7 = innerProd(x5,x2,M_position,l) / scaling_factor\n",
    "\n",
    "        xs = copy.deepcopy(v_onehot[5][0])\n",
    "        xs[1] = x[0]\n",
    "        xs[2] = x2[0]\n",
    "        xs[3] = x3[0]\n",
    "        xs[4] = x5[0]\n",
    "        xs[5] = x7[0]\n",
    "\n",
    "        out = mat_mul_forward(xs,H_sigmoid[0:1],scaling_factor)\n",
    "        out_rows.append(out)\n",
    "    return transpose(out_rows)[0]\n",
    "\n",
    "def load_linear_transformation(syn0_text,scaling_factor = 1000):\n",
    "    syn0_text *= scaling_factor\n",
    "    return linearTransformClient(syn0_text.T,getSecretKey(T_keys[len(syn0_text)-1]),T_keys[len(syn0_text)-1],l)\n",
    "\n",
    "def outer_product(x,y):\n",
    "    flip = False\n",
    "    if(len(x) < len(y)):\n",
    "        flip = True\n",
    "        tmp = x\n",
    "        x = y\n",
    "        y = tmp\n",
    "        \n",
    "    y_matrix = list()\n",
    "\n",
    "    for i in range(len(x)-1):\n",
    "        y_matrix.append(y)\n",
    "\n",
    "    y_matrix_transpose = transpose(y_matrix)\n",
    "\n",
    "    outer_result = list()\n",
    "    for i in range(len(x)-1):\n",
    "        outer_result.append(mat_mul_forward(x * onehot[len(x)-1][i],y_matrix_transpose,scaling_factor))\n",
    "    \n",
    "    if(flip):\n",
    "        return transpose(outer_result)\n",
    "    \n",
    "    return outer_result\n",
    "\n",
    "def mat_mul_forward(layer_1,syn1,scaling_factor):\n",
    "    \n",
    "    input_dim = len(layer_1)\n",
    "    output_dim = len(syn1)\n",
    "\n",
    "    buff = np.zeros(max(output_dim+1,input_dim+1))\n",
    "    buff[0:len(layer_1)] = layer_1\n",
    "    layer_1_c = buff\n",
    "    \n",
    "    syn1_c = list()\n",
    "    for i in range(len(syn1)):\n",
    "        buff = np.zeros(max(output_dim+1,input_dim+1))\n",
    "        buff[0:len(syn1[i])] = syn1[i]\n",
    "        syn1_c.append(buff)\n",
    "    \n",
    "    layer_2 = innerProd(syn1_c[0],layer_1_c,M_onehot[len(layer_1_c) - 2][0],l) / float(scaling_factor)\n",
    "    for i in range(len(syn1)-1):\n",
    "        layer_2 += innerProd(syn1_c[i+1],layer_1_c,M_onehot[len(layer_1_c) - 2][i+1],l) / float(scaling_factor)\n",
    "    return layer_2[0:output_dim+1]\n",
    "\n",
    "def elementwise_vector_mult(x,y,scaling_factor):\n",
    "    \n",
    "    y =[y]\n",
    "    \n",
    "    one_minus_layer_1 = transpose(y)\n",
    "\n",
    "    outer_result = list()\n",
    "    for i in range(len(x)-1):\n",
    "        outer_result.append(mat_mul_forward(x * onehot[len(x)-1][i],y,scaling_factor))\n",
    "        \n",
    "    return transpose(outer_result)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "# Let's tweak our network from before to model these phenomena\n",
    "class SentimentNetwork:\n",
    "    def __init__(self, reviews,labels,min_count = 10,polarity_cutoff = 0.1,hidden_nodes = 5, learning_rate = 0.01):\n",
    "       \n",
    "        np.random.seed(786)\n",
    "    \n",
    "        self.pre_process_data(reviews, polarity_cutoff, min_count)\n",
    "        \n",
    "        self.init_network(len(self.review_vocab),hidden_nodes, 1, learning_rate)\n",
    "        \n",
    "        \n",
    "    def pre_process_data(self,reviews, polarity_cutoff,min_count):\n",
    "        \n",
    "        print(\"Pre-processing data...\")\n",
    "        \n",
    "        positive_counts = Counter()\n",
    "        negative_counts = Counter()\n",
    "        total_counts = Counter()\n",
    "\n",
    "        for i in range(len(reviews)):\n",
    "            if(labels[i] == 'POSITIVE'):\n",
    "                for word in reviews[i].split(\" \"):\n",
    "                    positive_counts[word] += 1\n",
    "                    total_counts[word] += 1\n",
    "            else:\n",
    "                for word in reviews[i].split(\" \"):\n",
    "                    negative_counts[word] += 1\n",
    "                    total_counts[word] += 1\n",
    "\n",
    "        pos_neg_ratios = Counter()\n",
    "\n",
    "        for term,cnt in list(total_counts.most_common()):\n",
    "            if(cnt >= 100):\n",
    "                pos_neg_ratio = positive_counts[term] / float(negative_counts[term]+1)\n",
    "                pos_neg_ratios[term] = pos_neg_ratio\n",
    "\n",
    "        for word,ratio in pos_neg_ratios.most_common():\n",
    "            if(ratio > 1):\n",
    "                pos_neg_ratios[word] = np.log(ratio)\n",
    "            else:\n",
    "                pos_neg_ratios[word] = -np.log((1 / (ratio + 0.01)))\n",
    "        \n",
    "        review_vocab = set()\n",
    "        for review in reviews:\n",
    "            for word in review.split(\" \"):\n",
    "                if(total_counts[word] > min_count):\n",
    "                    if(word in pos_neg_ratios.keys()):\n",
    "                        if((pos_neg_ratios[word] >= polarity_cutoff) or (pos_neg_ratios[word] <= -polarity_cutoff)):\n",
    "                            review_vocab.add(word)\n",
    "                    else:\n",
    "                        review_vocab.add(word)\n",
    "        self.review_vocab = list(review_vocab)\n",
    "        \n",
    "        label_vocab = set()\n",
    "        for label in labels:\n",
    "            label_vocab.add(label)\n",
    "        \n",
    "        self.label_vocab = list(label_vocab)\n",
    "        \n",
    "        self.review_vocab_size = len(self.review_vocab)\n",
    "        self.label_vocab_size = len(self.label_vocab)\n",
    "        \n",
    "        self.word2index = {}\n",
    "        for i, word in enumerate(self.review_vocab):\n",
    "            self.word2index[word] = i\n",
    "        \n",
    "        self.label2index = {}\n",
    "        for i, label in enumerate(self.label_vocab):\n",
    "            self.label2index[label] = i\n",
    "         \n",
    "        \n",
    "    def init_network(self, input_nodes, hidden_nodes, output_nodes, learning_rate):\n",
    "        # Set number of nodes in input, hidden and output layers.\n",
    "        self.input_nodes = input_nodes\n",
    "        self.hidden_nodes = hidden_nodes\n",
    "        self.output_nodes = output_nodes\n",
    "\n",
    "        print(\"Initializing Weights...\")\n",
    "        self.weights_0_1_t = np.zeros((self.input_nodes,self.hidden_nodes))\n",
    "    \n",
    "        self.weights_1_2_t = np.random.normal(0.0, self.output_nodes**-0.5, \n",
    "                                                (self.hidden_nodes, self.output_nodes))\n",
    "        \n",
    "        print(\"Encrypting Weights...\")\n",
    "        self.weights_0_1 = list()\n",
    "        for i,row in enumerate(self.weights_0_1_t):\n",
    "            sys.stdout.write(\"\\rEncrypting Weights from Layer 0 to Layer 1:\" + str(float((i+1) * 100) / len(self.weights_0_1_t))[0:4] + \"% done\")\n",
    "            self.weights_0_1.append(one_way_encrypt_vector(row,scaling_factor).astype('int64'))\n",
    "        print(\"\")\n",
    "        \n",
    "        self.weights_1_2 = list()\n",
    "        for i,row in enumerate(self.weights_1_2_t):\n",
    "            sys.stdout.write(\"\\rEncrypting Weights from Layer 1 to Layer 2:\" + str(float((i+1) * 100) / len(self.weights_1_2_t))[0:4] + \"% done\")\n",
    "            self.weights_1_2.append(one_way_encrypt_vector(row,scaling_factor).astype('int64'))           \n",
    "        self.weights_1_2 = transpose(self.weights_1_2)\n",
    "        \n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        self.layer_0 = np.zeros((1,input_nodes))\n",
    "        self.layer_1 = np.zeros((1,hidden_nodes))\n",
    "        \n",
    "    def sigmoid(self,x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    \n",
    "    def sigmoid_output_2_derivative(self,output):\n",
    "        return output * (1 - output)\n",
    "    \n",
    "    def update_input_layer(self,review):\n",
    "\n",
    "        # clear out previous state, reset the layer to be all 0s\n",
    "        self.layer_0 *= 0\n",
    "        for word in review.split(\" \"):\n",
    "            self.layer_0[0][self.word2index[word]] = 1\n",
    "\n",
    "    def get_target_for_label(self,label):\n",
    "        if(label == 'POSITIVE'):\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "    def train(self, training_reviews_raw, training_labels):\n",
    "\n",
    "        training_reviews = list()\n",
    "        for review in training_reviews_raw:\n",
    "            indices = set()\n",
    "            for word in review.split(\" \"):\n",
    "                if(word in self.word2index.keys()):\n",
    "                    indices.add(self.word2index[word])\n",
    "            training_reviews.append(list(indices))\n",
    "\n",
    "        layer_1 = np.zeros_like(self.weights_0_1[0])\n",
    "\n",
    "        start = time.time()\n",
    "        correct_so_far = 0\n",
    "        total_pred = 0.5\n",
    "        for i in range(len(training_reviews_raw)):\n",
    "            review_indices = training_reviews[i]\n",
    "            label = training_labels[i]\n",
    "\n",
    "            layer_1 *= 0\n",
    "            for index in review_indices:\n",
    "                layer_1 += self.weights_0_1[index]\n",
    "            layer_1 = layer_1 / float(len(review_indices))\n",
    "            layer_1 = layer_1.astype('int64') # round to nearest integer\n",
    "\n",
    "            layer_2 = sigmoid(innerProd(layer_1,self.weights_1_2[0],M_onehot[len(layer_1) - 2][1],l) / float(scaling_factor))[0:2]\n",
    "\n",
    "            if(label == 'POSITIVE'):\n",
    "                layer_2_delta = layer_2 - (c_ones[len(layer_2) - 2] * scaling_factor)\n",
    "            else:\n",
    "                layer_2_delta = layer_2\n",
    "\n",
    "            weights_1_2_trans = transpose(self.weights_1_2)\n",
    "            layer_1_delta = mat_mul_forward(layer_2_delta,weights_1_2_trans,scaling_factor).astype('int64')\n",
    "\n",
    "            self.weights_1_2 -= np.array(outer_product(layer_2_delta,layer_1))  * self.learning_rate\n",
    "\n",
    "            for index in review_indices:\n",
    "                self.weights_0_1[index] -= (layer_1_delta * self.learning_rate).astype('int64')\n",
    "\n",
    "            # Decrypting for understanding how code is working\n",
    "            total_pred += (s_decrypt(layer_2)[0] / scaling_factor)\n",
    "            if((s_decrypt(layer_2)[0] / scaling_factor) >= (total_pred / float(i+2)) and label == 'POSITIVE'):\n",
    "                correct_so_far += 1\n",
    "            if((s_decrypt(layer_2)[0] / scaling_factor) < (total_pred / float(i+2)) and label == 'NEGATIVE'):\n",
    "                correct_so_far += 1\n",
    "\n",
    "            reviews_per_second = i / float(time.time() - start)\n",
    "\n",
    "            sys.stdout.write(\"\\rProgress:\" + str(100 * i/float(len(training_reviews_raw)))[:4] + \"% Speed(reviews/sec):\" + str(reviews_per_second)[0:5] + \" #Correct:\" + str(correct_so_far) + \" #Trained:\" + str(i+1) + \" Training Accuracy:\" + str(correct_so_far * 100 / float(i+1))[:4] + \"%\")\n",
    "            if(i % 100 == 0):\n",
    "                print(i)\n",
    "\n",
    "    \n",
    "    def test(self, testing_reviews, testing_labels):\n",
    "        \n",
    "        correct = 0\n",
    "        \n",
    "        start = time.time()\n",
    "        \n",
    "        for i in range(len(testing_reviews)):\n",
    "            pred = self.run(testing_reviews[i])\n",
    "            if(pred == testing_labels[i]):\n",
    "                correct += 1\n",
    "            \n",
    "            reviews_per_second = i / float(time.time() - start)\n",
    "            \n",
    "            sys.stdout.write(\"\\rProgress:\" + str(100 * i/float(len(testing_reviews)))[:4] \\\n",
    "                             + \"% Speed(reviews/sec):\" + str(reviews_per_second)[0:5] \\\n",
    "                            + \"% #Correct:\" + str(correct) + \" #Tested:\" + str(i+1) + \" Testing Accuracy:\" + str(correct * 100 / float(i+1))[:4] + \"%\")\n",
    "    \n",
    "    def run(self, review):\n",
    "        \n",
    "        # Input Layer\n",
    "\n",
    "        layer_1 = np.zeros_like(self.weights_0_1[0])\n",
    "        # Hidden layer\n",
    "        self.layer_1 *= 0\n",
    "        for index in review_indices:\n",
    "            self.layer_1 += self.weights_0_1[index]\n",
    "        layer_1 = self.layer_1 / float(len(review_indices))\n",
    "        layer_1 = self.layer_1.astype('int64') # round to nearest integer\n",
    "\n",
    "        layer_2 = self.sigmoid(innerProd(layer_1,self.weights_1_2[0],M_onehot[len(layer_1) - 2][1],l) / float(scaling_factor))[0:2]\n",
    "\n",
    "        \n",
    "        if((s_decrypt(layer_2)[0] / scaling_factor)) > 0.5:\n",
    "            return \"POSITIVE\"\n",
    "        else:\n",
    "            return \"NEGATIVE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-processing data...\n",
      "Initializing Weights...\n",
      "Encrypting Weights...\n",
      "Encrypting Weights from Layer 0 to Layer 1:100.% done\n",
      "Encrypting Weights from Layer 1 to Layer 2:100.% done"
     ]
    }
   ],
   "source": [
    "mlp = SentimentNetwork(reviews,labels,hidden_nodes=5, min_count=50,polarity_cutoff=0.2,learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saved_weights = (copy.deepcopy(mlp.weights_0_1),copy.deepcopy(mlp.weights_1_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress:0.0% Speed(reviews/sec):0.0 #Correct:1 #Trained:1 Training Accuracy:100.%0\n",
      "Progress:0.4% Speed(reviews/sec):1.698 #Correct:51 #Trained:101 Training Accuracy:50.4%100\n",
      "Progress:0.8% Speed(reviews/sec):1.738 #Correct:101 #Trained:201 Training Accuracy:50.2%200\n",
      "Progress:1.2% Speed(reviews/sec):1.755 #Correct:160 #Trained:301 Training Accuracy:53.1%300\n",
      "Progress:1.6% Speed(reviews/sec):1.766 #Correct:226 #Trained:401 Training Accuracy:56.3%400\n",
      "Progress:2.0% Speed(reviews/sec):1.771 #Correct:287 #Trained:501 Training Accuracy:57.2%500\n",
      "Progress:2.4% Speed(reviews/sec):1.776 #Correct:351 #Trained:601 Training Accuracy:58.4%600\n",
      "Progress:2.8% Speed(reviews/sec):1.771 #Correct:420 #Trained:701 Training Accuracy:59.9%700\n",
      "Progress:3.2% Speed(reviews/sec):1.768 #Correct:493 #Trained:801 Training Accuracy:61.5%800\n",
      "Progress:3.6% Speed(reviews/sec):1.767 #Correct:567 #Trained:901 Training Accuracy:62.9%900\n",
      "Progress:4.0% Speed(reviews/sec):1.767 #Correct:645 #Trained:1001 Training Accuracy:64.4%1000\n",
      "Progress:4.4% Speed(reviews/sec):1.761 #Correct:730 #Trained:1101 Training Accuracy:66.3%1100\n",
      "Progress:4.8% Speed(reviews/sec):1.748 #Correct:808 #Trained:1201 Training Accuracy:67.2%1200\n",
      "Progress:5.2% Speed(reviews/sec):1.734 #Correct:882 #Trained:1301 Training Accuracy:67.7%1300\n",
      "Progress:5.6% Speed(reviews/sec):1.724 #Correct:961 #Trained:1401 Training Accuracy:68.5%1400\n",
      "Progress:6.0% Speed(reviews/sec):1.711 #Correct:1038 #Trained:1501 Training Accuracy:69.1%1500\n",
      "Progress:6.4% Speed(reviews/sec):1.699 #Correct:1119 #Trained:1601 Training Accuracy:69.8%1600\n",
      "Progress:6.8% Speed(reviews/sec):1.695 #Correct:1191 #Trained:1701 Training Accuracy:70.0%1700\n",
      "Progress:7.2% Speed(reviews/sec):1.689 #Correct:1269 #Trained:1801 Training Accuracy:70.4%1800\n",
      "Progress:7.6% Speed(reviews/sec):1.690 #Correct:1347 #Trained:1901 Training Accuracy:70.8%1900\n",
      "Progress:8.0% Speed(reviews/sec):1.685 #Correct:1421 #Trained:2001 Training Accuracy:71.0%2000\n",
      "Progress:8.4% Speed(reviews/sec):1.686 #Correct:1502 #Trained:2101 Training Accuracy:71.4%2100\n",
      "Progress:8.8% Speed(reviews/sec):1.685 #Correct:1584 #Trained:2201 Training Accuracy:71.9%2200\n",
      "Progress:9.2% Speed(reviews/sec):1.678 #Correct:1651 #Trained:2301 Training Accuracy:71.7%2300\n",
      "Progress:9.6% Speed(reviews/sec):1.672 #Correct:1722 #Trained:2401 Training Accuracy:71.7%2400\n",
      "Progress:10.0% Speed(reviews/sec):1.671 #Correct:1796 #Trained:2501 Training Accuracy:71.8%2500\n",
      "Progress:10.4% Speed(reviews/sec):1.673 #Correct:1881 #Trained:2601 Training Accuracy:72.3%2600\n",
      "Progress:10.8% Speed(reviews/sec):1.676 #Correct:1954 #Trained:2701 Training Accuracy:72.3%2700\n",
      "Progress:11.2% Speed(reviews/sec):1.678 #Correct:2034 #Trained:2801 Training Accuracy:72.6%2800\n",
      "Progress:11.6% Speed(reviews/sec):1.680 #Correct:2115 #Trained:2901 Training Accuracy:72.9%2900\n",
      "Progress:12.0% Speed(reviews/sec):1.681 #Correct:2188 #Trained:3001 Training Accuracy:72.9%3000\n",
      "Progress:12.4% Speed(reviews/sec):1.681 #Correct:2271 #Trained:3101 Training Accuracy:73.2%3100\n",
      "Progress:12.8% Speed(reviews/sec):1.682 #Correct:2352 #Trained:3201 Training Accuracy:73.4%3200\n",
      "Progress:13.2% Speed(reviews/sec):1.681 #Correct:2413 #Trained:3301 Training Accuracy:73.0%3300\n",
      "Progress:13.6% Speed(reviews/sec):1.681 #Correct:2489 #Trained:3401 Training Accuracy:73.1%3400\n",
      "Progress:14.0% Speed(reviews/sec):1.684 #Correct:2564 #Trained:3501 Training Accuracy:73.2%3500\n",
      "Progress:14.4% Speed(reviews/sec):1.687 #Correct:2633 #Trained:3601 Training Accuracy:73.1%3600\n",
      "Progress:14.8% Speed(reviews/sec):1.689 #Correct:2706 #Trained:3701 Training Accuracy:73.1%3700\n",
      "Progress:15.2% Speed(reviews/sec):1.692 #Correct:2774 #Trained:3801 Training Accuracy:72.9%3800\n",
      "Progress:15.6% Speed(reviews/sec):1.695 #Correct:2841 #Trained:3901 Training Accuracy:72.8%3900\n",
      "Progress:16.0% Speed(reviews/sec):1.696 #Correct:2922 #Trained:4001 Training Accuracy:73.0%4000\n",
      "Progress:16.4% Speed(reviews/sec):1.697 #Correct:2997 #Trained:4101 Training Accuracy:73.0%4100\n",
      "Progress:16.8% Speed(reviews/sec):1.698 #Correct:3072 #Trained:4201 Training Accuracy:73.1%4200\n",
      "Progress:17.2% Speed(reviews/sec):1.700 #Correct:3143 #Trained:4301 Training Accuracy:73.0%4300\n",
      "Progress:17.6% Speed(reviews/sec):1.700 #Correct:3216 #Trained:4401 Training Accuracy:73.0%4400\n",
      "Progress:18.0% Speed(reviews/sec):1.702 #Correct:3287 #Trained:4501 Training Accuracy:73.0%4500\n",
      "Progress:18.4% Speed(reviews/sec):1.703 #Correct:3355 #Trained:4601 Training Accuracy:72.9%4600\n",
      "Progress:18.8% Speed(reviews/sec):1.704 #Correct:3432 #Trained:4701 Training Accuracy:73.0%4700\n",
      "Progress:19.2% Speed(reviews/sec):1.705 #Correct:3507 #Trained:4801 Training Accuracy:73.0%4800\n",
      "Progress:19.6% Speed(reviews/sec):1.706 #Correct:3579 #Trained:4901 Training Accuracy:73.0%4900\n",
      "Progress:20.0% Speed(reviews/sec):1.707 #Correct:3648 #Trained:5001 Training Accuracy:72.9%5000\n",
      "Progress:20.4% Speed(reviews/sec):1.708 #Correct:3729 #Trained:5101 Training Accuracy:73.1%5100\n",
      "Progress:20.8% Speed(reviews/sec):1.709 #Correct:3808 #Trained:5201 Training Accuracy:73.2%5200\n",
      "Progress:21.2% Speed(reviews/sec):1.709 #Correct:3883 #Trained:5301 Training Accuracy:73.2%5300\n",
      "Progress:21.6% Speed(reviews/sec):1.710 #Correct:3959 #Trained:5401 Training Accuracy:73.3%5400\n",
      "Progress:22.0% Speed(reviews/sec):1.711 #Correct:4026 #Trained:5501 Training Accuracy:73.1%5500\n",
      "Progress:22.4% Speed(reviews/sec):1.712 #Correct:4098 #Trained:5601 Training Accuracy:73.1%5600\n",
      "Progress:22.8% Speed(reviews/sec):1.712 #Correct:4171 #Trained:5701 Training Accuracy:73.1%5700\n",
      "Progress:23.2% Speed(reviews/sec):1.713 #Correct:4246 #Trained:5801 Training Accuracy:73.1%5800\n",
      "Progress:23.6% Speed(reviews/sec):1.714 #Correct:4318 #Trained:5901 Training Accuracy:73.1%5900\n",
      "Progress:24.0% Speed(reviews/sec):1.714 #Correct:4393 #Trained:6001 Training Accuracy:73.2%6000\n",
      "Progress:24.4% Speed(reviews/sec):1.715 #Correct:4465 #Trained:6101 Training Accuracy:73.1%6100\n",
      "Progress:24.8% Speed(reviews/sec):1.715 #Correct:4552 #Trained:6201 Training Accuracy:73.4%6200\n",
      "Progress:25.2% Speed(reviews/sec):1.715 #Correct:4639 #Trained:6301 Training Accuracy:73.6%6300\n",
      "Progress:25.6% Speed(reviews/sec):1.716 #Correct:4711 #Trained:6401 Training Accuracy:73.5%6400\n",
      "Progress:26.0% Speed(reviews/sec):1.716 #Correct:4798 #Trained:6501 Training Accuracy:73.8%6500\n",
      "Progress:26.4% Speed(reviews/sec):1.717 #Correct:4874 #Trained:6601 Training Accuracy:73.8%6600\n",
      "Progress:26.8% Speed(reviews/sec):1.717 #Correct:4957 #Trained:6701 Training Accuracy:73.9%6700\n",
      "Progress:27.2% Speed(reviews/sec):1.717 #Correct:5032 #Trained:6801 Training Accuracy:73.9%6800\n",
      "Progress:27.6% Speed(reviews/sec):1.717 #Correct:5117 #Trained:6901 Training Accuracy:74.1%6900\n",
      "Progress:28.0% Speed(reviews/sec):1.718 #Correct:5202 #Trained:7001 Training Accuracy:74.3%7000\n",
      "Progress:28.4% Speed(reviews/sec):1.718 #Correct:5280 #Trained:7101 Training Accuracy:74.3%7100\n",
      "Progress:28.8% Speed(reviews/sec):1.719 #Correct:5362 #Trained:7201 Training Accuracy:74.4%7200\n",
      "Progress:29.2% Speed(reviews/sec):1.719 #Correct:5447 #Trained:7301 Training Accuracy:74.6%7300\n",
      "Progress:29.6% Speed(reviews/sec):1.719 #Correct:5521 #Trained:7401 Training Accuracy:74.5%7400\n",
      "Progress:30.0% Speed(reviews/sec):1.719 #Correct:5597 #Trained:7501 Training Accuracy:74.6%7500\n",
      "Progress:30.4% Speed(reviews/sec):1.719 #Correct:5675 #Trained:7601 Training Accuracy:74.6%7600\n",
      "Progress:30.8% Speed(reviews/sec):1.718 #Correct:5759 #Trained:7701 Training Accuracy:74.7%7700\n",
      "Progress:31.2% Speed(reviews/sec):1.717 #Correct:5838 #Trained:7801 Training Accuracy:74.8%7800\n",
      "Progress:31.6% Speed(reviews/sec):1.717 #Correct:5915 #Trained:7901 Training Accuracy:74.8%7900\n",
      "Progress:32.0% Speed(reviews/sec):1.718 #Correct:5996 #Trained:8001 Training Accuracy:74.9%8000\n",
      "Progress:32.4% Speed(reviews/sec):1.718 #Correct:6070 #Trained:8101 Training Accuracy:74.9%8100\n",
      "Progress:32.8% Speed(reviews/sec):1.719 #Correct:6145 #Trained:8201 Training Accuracy:74.9%8200\n",
      "Progress:33.2% Speed(reviews/sec):1.719 #Correct:6221 #Trained:8301 Training Accuracy:74.9%8300\n",
      "Progress:33.6% Speed(reviews/sec):1.719 #Correct:6290 #Trained:8401 Training Accuracy:74.8%8400\n",
      "Progress:34.0% Speed(reviews/sec):1.720 #Correct:6366 #Trained:8501 Training Accuracy:74.8%8500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress:34.4% Speed(reviews/sec):1.720 #Correct:6446 #Trained:8601 Training Accuracy:74.9%8600\n",
      "Progress:34.8% Speed(reviews/sec):1.721 #Correct:6521 #Trained:8701 Training Accuracy:74.9%8700\n",
      "Progress:35.2% Speed(reviews/sec):1.722 #Correct:6594 #Trained:8801 Training Accuracy:74.9%8800\n",
      "Progress:35.6% Speed(reviews/sec):1.722 #Correct:6676 #Trained:8901 Training Accuracy:75.0%8900\n",
      "Progress:36.0% Speed(reviews/sec):1.723 #Correct:6757 #Trained:9001 Training Accuracy:75.0%9000\n",
      "Progress:36.4% Speed(reviews/sec):1.723 #Correct:6835 #Trained:9101 Training Accuracy:75.1%9100\n",
      "Progress:36.8% Speed(reviews/sec):1.724 #Correct:6920 #Trained:9201 Training Accuracy:75.2%9200\n",
      "Progress:37.2% Speed(reviews/sec):1.724 #Correct:7000 #Trained:9301 Training Accuracy:75.2%9300\n",
      "Progress:37.6% Speed(reviews/sec):1.724 #Correct:7072 #Trained:9401 Training Accuracy:75.2%9400\n",
      "Progress:38.0% Speed(reviews/sec):1.725 #Correct:7152 #Trained:9501 Training Accuracy:75.2%9500\n",
      "Progress:38.4% Speed(reviews/sec):1.725 #Correct:7236 #Trained:9601 Training Accuracy:75.3%9600\n",
      "Progress:38.8% Speed(reviews/sec):1.726 #Correct:7316 #Trained:9701 Training Accuracy:75.4%9700\n",
      "Progress:39.2% Speed(reviews/sec):1.726 #Correct:7401 #Trained:9801 Training Accuracy:75.5%9800\n",
      "Progress:39.6% Speed(reviews/sec):1.727 #Correct:7474 #Trained:9901 Training Accuracy:75.4%9900\n",
      "Progress:40.0% Speed(reviews/sec):1.727 #Correct:7545 #Trained:10001 Training Accuracy:75.4%10000\n",
      "Progress:40.4% Speed(reviews/sec):1.728 #Correct:7618 #Trained:10101 Training Accuracy:75.4%10100\n",
      "Progress:40.8% Speed(reviews/sec):1.728 #Correct:7700 #Trained:10201 Training Accuracy:75.4%10200\n",
      "Progress:41.2% Speed(reviews/sec):1.728 #Correct:7778 #Trained:10301 Training Accuracy:75.5%10300\n",
      "Progress:41.6% Speed(reviews/sec):1.729 #Correct:7858 #Trained:10401 Training Accuracy:75.5%10400\n",
      "Progress:42.0% Speed(reviews/sec):1.729 #Correct:7935 #Trained:10501 Training Accuracy:75.5%10500\n",
      "Progress:42.4% Speed(reviews/sec):1.729 #Correct:8011 #Trained:10601 Training Accuracy:75.5%10600\n",
      "Progress:42.8% Speed(reviews/sec):1.729 #Correct:8095 #Trained:10701 Training Accuracy:75.6%10700\n",
      "Progress:43.2% Speed(reviews/sec):1.729 #Correct:8167 #Trained:10801 Training Accuracy:75.6%10800\n",
      "Progress:43.6% Speed(reviews/sec):1.730 #Correct:8237 #Trained:10901 Training Accuracy:75.5%10900\n",
      "Progress:44.0% Speed(reviews/sec):1.730 #Correct:8318 #Trained:11001 Training Accuracy:75.6%11000\n",
      "Progress:44.4% Speed(reviews/sec):1.730 #Correct:8401 #Trained:11101 Training Accuracy:75.6%11100\n",
      "Progress:44.8% Speed(reviews/sec):1.730 #Correct:8471 #Trained:11201 Training Accuracy:75.6%11200\n",
      "Progress:45.2% Speed(reviews/sec):1.730 #Correct:8538 #Trained:11301 Training Accuracy:75.5%11300\n",
      "Progress:45.6% Speed(reviews/sec):1.731 #Correct:8618 #Trained:11401 Training Accuracy:75.5%11400\n",
      "Progress:46.0% Speed(reviews/sec):1.731 #Correct:8698 #Trained:11501 Training Accuracy:75.6%11500\n",
      "Progress:46.4% Speed(reviews/sec):1.731 #Correct:8774 #Trained:11601 Training Accuracy:75.6%11600\n",
      "Progress:46.8% Speed(reviews/sec):1.731 #Correct:8857 #Trained:11701 Training Accuracy:75.6%11700\n",
      "Progress:47.2% Speed(reviews/sec):1.731 #Correct:8931 #Trained:11801 Training Accuracy:75.6%11800\n",
      "Progress:47.6% Speed(reviews/sec):1.731 #Correct:9011 #Trained:11901 Training Accuracy:75.7%11900\n",
      "Progress:48.0% Speed(reviews/sec):1.731 #Correct:9086 #Trained:12001 Training Accuracy:75.7%12000\n",
      "Progress:48.4% Speed(reviews/sec):1.732 #Correct:9164 #Trained:12101 Training Accuracy:75.7%12100\n",
      "Progress:48.8% Speed(reviews/sec):1.731 #Correct:9243 #Trained:12201 Training Accuracy:75.7%12200\n",
      "Progress:49.2% Speed(reviews/sec):1.731 #Correct:9320 #Trained:12301 Training Accuracy:75.7%12300\n",
      "Progress:49.6% Speed(reviews/sec):1.731 #Correct:9405 #Trained:12401 Training Accuracy:75.8%12400\n",
      "Progress:50.0% Speed(reviews/sec):1.731 #Correct:9487 #Trained:12501 Training Accuracy:75.8%12500\n",
      "Progress:50.4% Speed(reviews/sec):1.731 #Correct:9571 #Trained:12601 Training Accuracy:75.9%12600\n",
      "Progress:50.8% Speed(reviews/sec):1.731 #Correct:9649 #Trained:12701 Training Accuracy:75.9%12700\n",
      "Progress:51.2% Speed(reviews/sec):1.730 #Correct:9733 #Trained:12801 Training Accuracy:76.0%12800\n",
      "Progress:51.6% Speed(reviews/sec):1.731 #Correct:9807 #Trained:12901 Training Accuracy:76.0%12900\n",
      "Progress:52.0% Speed(reviews/sec):1.731 #Correct:9884 #Trained:13001 Training Accuracy:76.0%13000\n",
      "Progress:52.4% Speed(reviews/sec):1.731 #Correct:9959 #Trained:13101 Training Accuracy:76.0%13100\n",
      "Progress:52.8% Speed(reviews/sec):1.731 #Correct:10038 #Trained:13201 Training Accuracy:76.0%13200\n",
      "Progress:53.2% Speed(reviews/sec):1.731 #Correct:10112 #Trained:13301 Training Accuracy:76.0%13300\n",
      "Progress:53.6% Speed(reviews/sec):1.732 #Correct:10178 #Trained:13401 Training Accuracy:75.9%13400\n",
      "Progress:54.0% Speed(reviews/sec):1.732 #Correct:10263 #Trained:13501 Training Accuracy:76.0%13500\n",
      "Progress:54.4% Speed(reviews/sec):1.732 #Correct:10342 #Trained:13601 Training Accuracy:76.0%13600\n",
      "Progress:54.8% Speed(reviews/sec):1.732 #Correct:10418 #Trained:13701 Training Accuracy:76.0%13700\n",
      "Progress:55.2% Speed(reviews/sec):1.732 #Correct:10493 #Trained:13801 Training Accuracy:76.0%13800\n",
      "Progress:55.6% Speed(reviews/sec):1.732 #Correct:10569 #Trained:13901 Training Accuracy:76.0%13900\n",
      "Progress:56.0% Speed(reviews/sec):1.732 #Correct:10643 #Trained:14001 Training Accuracy:76.0%14000\n",
      "Progress:56.4% Speed(reviews/sec):1.732 #Correct:10716 #Trained:14101 Training Accuracy:75.9%14100\n",
      "Progress:56.8% Speed(reviews/sec):1.732 #Correct:10789 #Trained:14201 Training Accuracy:75.9%14200\n",
      "Progress:57.2% Speed(reviews/sec):1.732 #Correct:10867 #Trained:14301 Training Accuracy:75.9%14300\n",
      "Progress:57.6% Speed(reviews/sec):1.732 #Correct:10929 #Trained:14401 Training Accuracy:75.8%14400\n",
      "Progress:58.0% Speed(reviews/sec):1.732 #Correct:11000 #Trained:14501 Training Accuracy:75.8%14500\n",
      "Progress:58.4% Speed(reviews/sec):1.732 #Correct:11078 #Trained:14601 Training Accuracy:75.8%14600\n",
      "Progress:58.8% Speed(reviews/sec):1.732 #Correct:11147 #Trained:14701 Training Accuracy:75.8%14700\n",
      "Progress:59.2% Speed(reviews/sec):1.732 #Correct:11227 #Trained:14801 Training Accuracy:75.8%14800\n",
      "Progress:59.6% Speed(reviews/sec):1.732 #Correct:11308 #Trained:14901 Training Accuracy:75.8%14900\n",
      "Progress:60.0% Speed(reviews/sec):1.732 #Correct:11381 #Trained:15001 Training Accuracy:75.8%15000\n",
      "Progress:60.4% Speed(reviews/sec):1.732 #Correct:11452 #Trained:15101 Training Accuracy:75.8%15100\n",
      "Progress:60.8% Speed(reviews/sec):1.732 #Correct:11522 #Trained:15201 Training Accuracy:75.7%15200\n",
      "Progress:61.2% Speed(reviews/sec):1.732 #Correct:11600 #Trained:15301 Training Accuracy:75.8%15300\n",
      "Progress:61.6% Speed(reviews/sec):1.732 #Correct:11675 #Trained:15401 Training Accuracy:75.8%15400\n",
      "Progress:62.0% Speed(reviews/sec):1.732 #Correct:11748 #Trained:15501 Training Accuracy:75.7%15500\n",
      "Progress:62.4% Speed(reviews/sec):1.732 #Correct:11822 #Trained:15601 Training Accuracy:75.7%15600\n",
      "Progress:62.8% Speed(reviews/sec):1.732 #Correct:11894 #Trained:15701 Training Accuracy:75.7%15700\n",
      "Progress:63.2% Speed(reviews/sec):1.732 #Correct:11961 #Trained:15801 Training Accuracy:75.6%15800\n",
      "Progress:63.6% Speed(reviews/sec):1.732 #Correct:12044 #Trained:15901 Training Accuracy:75.7%15900\n",
      "Progress:64.0% Speed(reviews/sec):1.732 #Correct:12110 #Trained:16001 Training Accuracy:75.6%16000\n",
      "Progress:64.4% Speed(reviews/sec):1.732 #Correct:12177 #Trained:16101 Training Accuracy:75.6%16100\n",
      "Progress:64.8% Speed(reviews/sec):1.732 #Correct:12260 #Trained:16201 Training Accuracy:75.6%16200\n",
      "Progress:65.2% Speed(reviews/sec):1.732 #Correct:12333 #Trained:16301 Training Accuracy:75.6%16300\n",
      "Progress:65.6% Speed(reviews/sec):1.732 #Correct:12396 #Trained:16401 Training Accuracy:75.5%16400\n",
      "Progress:66.0% Speed(reviews/sec):1.732 #Correct:12477 #Trained:16501 Training Accuracy:75.6%16500\n",
      "Progress:66.4% Speed(reviews/sec):1.732 #Correct:12552 #Trained:16601 Training Accuracy:75.6%16600\n",
      "Progress:66.8% Speed(reviews/sec):1.731 #Correct:12624 #Trained:16701 Training Accuracy:75.5%16700\n",
      "Progress:67.2% Speed(reviews/sec):1.731 #Correct:12687 #Trained:16801 Training Accuracy:75.5%16800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress:67.6% Speed(reviews/sec):1.731 #Correct:12749 #Trained:16901 Training Accuracy:75.4%16900\n",
      "Progress:68.0% Speed(reviews/sec):1.731 #Correct:12819 #Trained:17001 Training Accuracy:75.4%17000\n",
      "Progress:68.4% Speed(reviews/sec):1.732 #Correct:12892 #Trained:17101 Training Accuracy:75.3%17100\n",
      "Progress:68.8% Speed(reviews/sec):1.732 #Correct:12974 #Trained:17201 Training Accuracy:75.4%17200\n",
      "Progress:69.2% Speed(reviews/sec):1.732 #Correct:13045 #Trained:17301 Training Accuracy:75.4%17300\n",
      "Progress:69.6% Speed(reviews/sec):1.732 #Correct:13114 #Trained:17401 Training Accuracy:75.3%17400\n",
      "Progress:70.0% Speed(reviews/sec):1.732 #Correct:13191 #Trained:17501 Training Accuracy:75.3%17500\n",
      "Progress:70.4% Speed(reviews/sec):1.732 #Correct:13269 #Trained:17601 Training Accuracy:75.3%17600\n",
      "Progress:70.8% Speed(reviews/sec):1.733 #Correct:13344 #Trained:17701 Training Accuracy:75.3%17700\n",
      "Progress:71.2% Speed(reviews/sec):1.733 #Correct:13426 #Trained:17801 Training Accuracy:75.4%17800\n",
      "Progress:71.6% Speed(reviews/sec):1.733 #Correct:13505 #Trained:17901 Training Accuracy:75.4%17900\n",
      "Progress:72.0% Speed(reviews/sec):1.733 #Correct:13582 #Trained:18001 Training Accuracy:75.4%18000\n",
      "Progress:72.4% Speed(reviews/sec):1.733 #Correct:13648 #Trained:18101 Training Accuracy:75.3%18100\n",
      "Progress:72.8% Speed(reviews/sec):1.733 #Correct:13731 #Trained:18201 Training Accuracy:75.4%18200\n",
      "Progress:73.2% Speed(reviews/sec):1.733 #Correct:13805 #Trained:18301 Training Accuracy:75.4%18300\n",
      "Progress:73.6% Speed(reviews/sec):1.733 #Correct:13873 #Trained:18401 Training Accuracy:75.3%18400\n",
      "Progress:74.0% Speed(reviews/sec):1.733 #Correct:13954 #Trained:18501 Training Accuracy:75.4%18500\n",
      "Progress:74.4% Speed(reviews/sec):1.733 #Correct:14033 #Trained:18601 Training Accuracy:75.4%18600\n",
      "Progress:74.8% Speed(reviews/sec):1.733 #Correct:14119 #Trained:18701 Training Accuracy:75.4%18700\n",
      "Progress:75.2% Speed(reviews/sec):1.733 #Correct:14197 #Trained:18801 Training Accuracy:75.5%18800\n",
      "Progress:75.6% Speed(reviews/sec):1.733 #Correct:14272 #Trained:18901 Training Accuracy:75.5%18900\n",
      "Progress:76.0% Speed(reviews/sec):1.732 #Correct:14325 #Trained:19001 Training Accuracy:75.3%19000\n",
      "Progress:76.4% Speed(reviews/sec):1.732 #Correct:14402 #Trained:19101 Training Accuracy:75.3%19100\n",
      "Progress:76.8% Speed(reviews/sec):1.732 #Correct:14475 #Trained:19201 Training Accuracy:75.3%19200\n",
      "Progress:77.2% Speed(reviews/sec):1.732 #Correct:14557 #Trained:19301 Training Accuracy:75.4%19300\n",
      "Progress:77.6% Speed(reviews/sec):1.732 #Correct:14632 #Trained:19401 Training Accuracy:75.4%19400\n",
      "Progress:78.0% Speed(reviews/sec):1.732 #Correct:14715 #Trained:19501 Training Accuracy:75.4%19500\n",
      "Progress:78.4% Speed(reviews/sec):1.732 #Correct:14785 #Trained:19601 Training Accuracy:75.4%19600\n",
      "Progress:78.8% Speed(reviews/sec):1.732 #Correct:14852 #Trained:19701 Training Accuracy:75.3%19700\n",
      "Progress:79.2% Speed(reviews/sec):1.732 #Correct:14926 #Trained:19801 Training Accuracy:75.3%19800\n",
      "Progress:79.6% Speed(reviews/sec):1.732 #Correct:15002 #Trained:19901 Training Accuracy:75.3%19900\n",
      "Progress:80.0% Speed(reviews/sec):1.733 #Correct:15068 #Trained:20001 Training Accuracy:75.3%20000\n",
      "Progress:80.4% Speed(reviews/sec):1.733 #Correct:15147 #Trained:20101 Training Accuracy:75.3%20100\n",
      "Progress:80.8% Speed(reviews/sec):1.733 #Correct:15224 #Trained:20201 Training Accuracy:75.3%20200\n",
      "Progress:81.2% Speed(reviews/sec):1.733 #Correct:15296 #Trained:20301 Training Accuracy:75.3%20300\n",
      "Progress:81.6% Speed(reviews/sec):1.733 #Correct:15366 #Trained:20401 Training Accuracy:75.3%20400\n",
      "Progress:82.0% Speed(reviews/sec):1.733 #Correct:15439 #Trained:20501 Training Accuracy:75.3%20500\n",
      "Progress:82.4% Speed(reviews/sec):1.733 #Correct:15510 #Trained:20601 Training Accuracy:75.2%20600\n",
      "Progress:82.8% Speed(reviews/sec):1.733 #Correct:15582 #Trained:20701 Training Accuracy:75.2%20700\n",
      "Progress:83.2% Speed(reviews/sec):1.733 #Correct:15654 #Trained:20801 Training Accuracy:75.2%20800\n",
      "Progress:83.6% Speed(reviews/sec):1.732 #Correct:15722 #Trained:20901 Training Accuracy:75.2%20900\n",
      "Progress:84.0% Speed(reviews/sec):1.732 #Correct:15793 #Trained:21001 Training Accuracy:75.2%21000\n",
      "Progress:84.4% Speed(reviews/sec):1.732 #Correct:15876 #Trained:21101 Training Accuracy:75.2%21100\n",
      "Progress:84.8% Speed(reviews/sec):1.732 #Correct:15951 #Trained:21201 Training Accuracy:75.2%21200\n",
      "Progress:85.2% Speed(reviews/sec):1.732 #Correct:16027 #Trained:21301 Training Accuracy:75.2%21300\n",
      "Progress:85.6% Speed(reviews/sec):1.732 #Correct:16099 #Trained:21401 Training Accuracy:75.2%21400\n",
      "Progress:86.0% Speed(reviews/sec):1.732 #Correct:16178 #Trained:21501 Training Accuracy:75.2%21500\n",
      "Progress:86.4% Speed(reviews/sec):1.731 #Correct:16253 #Trained:21601 Training Accuracy:75.2%21600\n",
      "Progress:86.8% Speed(reviews/sec):1.731 #Correct:16329 #Trained:21701 Training Accuracy:75.2%21700\n",
      "Progress:87.2% Speed(reviews/sec):1.731 #Correct:16401 #Trained:21801 Training Accuracy:75.2%21800\n",
      "Progress:87.6% Speed(reviews/sec):1.731 #Correct:16476 #Trained:21901 Training Accuracy:75.2%21900\n",
      "Progress:88.0% Speed(reviews/sec):1.731 #Correct:16556 #Trained:22001 Training Accuracy:75.2%22000\n",
      "Progress:88.4% Speed(reviews/sec):1.732 #Correct:16632 #Trained:22101 Training Accuracy:75.2%22100\n",
      "Progress:88.8% Speed(reviews/sec):1.732 #Correct:16707 #Trained:22201 Training Accuracy:75.2%22200\n",
      "Progress:89.2% Speed(reviews/sec):1.731 #Correct:16786 #Trained:22301 Training Accuracy:75.2%22300\n",
      "Progress:89.6% Speed(reviews/sec):1.731 #Correct:16857 #Trained:22401 Training Accuracy:75.2%22400\n",
      "Progress:90.0% Speed(reviews/sec):1.731 #Correct:16936 #Trained:22501 Training Accuracy:75.2%22500\n",
      "Progress:90.4% Speed(reviews/sec):1.731 #Correct:16993 #Trained:22601 Training Accuracy:75.1%22600\n",
      "Progress:90.8% Speed(reviews/sec):1.731 #Correct:17078 #Trained:22701 Training Accuracy:75.2%22700\n",
      "Progress:91.2% Speed(reviews/sec):1.731 #Correct:17159 #Trained:22801 Training Accuracy:75.2%22800\n",
      "Progress:91.6% Speed(reviews/sec):1.731 #Correct:17237 #Trained:22901 Training Accuracy:75.2%22900\n",
      "Progress:92.0% Speed(reviews/sec):1.731 #Correct:17307 #Trained:23001 Training Accuracy:75.2%23000\n",
      "Progress:92.4% Speed(reviews/sec):1.731 #Correct:17384 #Trained:23101 Training Accuracy:75.2%23100\n",
      "Progress:92.8% Speed(reviews/sec):1.731 #Correct:17461 #Trained:23201 Training Accuracy:75.2%23200\n",
      "Progress:93.2% Speed(reviews/sec):1.731 #Correct:17532 #Trained:23301 Training Accuracy:75.2%23300\n",
      "Progress:93.6% Speed(reviews/sec):1.731 #Correct:17598 #Trained:23401 Training Accuracy:75.2%23400\n",
      "Progress:94.0% Speed(reviews/sec):1.731 #Correct:17670 #Trained:23501 Training Accuracy:75.1%23500\n",
      "Progress:94.4% Speed(reviews/sec):1.731 #Correct:17750 #Trained:23601 Training Accuracy:75.2%23600\n",
      "Progress:94.8% Speed(reviews/sec):1.731 #Correct:17828 #Trained:23701 Training Accuracy:75.2%23700\n",
      "Progress:95.2% Speed(reviews/sec):1.731 #Correct:17915 #Trained:23801 Training Accuracy:75.2%23800\n",
      "Progress:95.6% Speed(reviews/sec):1.731 #Correct:17996 #Trained:23901 Training Accuracy:75.2%23900\n",
      "Progress:96.0% Speed(reviews/sec):1.731 #Correct:18081 #Trained:24001 Training Accuracy:75.3%24000\n",
      "Progress:96.4% Speed(reviews/sec):1.731 #Correct:18159 #Trained:24101 Training Accuracy:75.3%24100\n",
      "Progress:96.8% Speed(reviews/sec):1.731 #Correct:18231 #Trained:24201 Training Accuracy:75.3%24200\n",
      "Progress:97.2% Speed(reviews/sec):1.731 #Correct:18317 #Trained:24301 Training Accuracy:75.3%24300\n",
      "Progress:97.6% Speed(reviews/sec):1.731 #Correct:18389 #Trained:24401 Training Accuracy:75.3%24400\n",
      "Progress:98.0% Speed(reviews/sec):1.731 #Correct:18461 #Trained:24501 Training Accuracy:75.3%24500\n",
      "Progress:98.4% Speed(reviews/sec):1.731 #Correct:18537 #Trained:24601 Training Accuracy:75.3%24600\n",
      "Progress:98.8% Speed(reviews/sec):1.731 #Correct:18596 #Trained:24701 Training Accuracy:75.2%24700\n",
      "Progress:99.2% Speed(reviews/sec):1.731 #Correct:18659 #Trained:24801 Training Accuracy:75.2%24800\n",
      "Progress:99.6% Speed(reviews/sec):1.731 #Correct:18729 #Trained:24901 Training Accuracy:75.2%24900\n",
      "Progress:99.9% Speed(reviews/sec):1.731 #Correct:18799 #Trained:25000 Training Accuracy:75.1%"
     ]
    }
   ],
   "source": [
    "mlp.weights_0_1 = copy.deepcopy(saved_weights[0])\n",
    "mlp.weights_1_2 = copy.deepcopy(saved_weights[1])\n",
    "mlp.learning_rate = 0.001\n",
    "mlp.train(reviews,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (1,5) (6,) (1,5) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-79-91f34e72fc62>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreviews\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-53-dc2ec63a3a45>\u001b[0m in \u001b[0;36mtest\u001b[1;34m(self, testing_reviews, testing_labels)\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtesting_reviews\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 187\u001b[1;33m             \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtesting_reviews\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    188\u001b[0m             \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mtesting_labels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m                 \u001b[0mcorrect\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-53-dc2ec63a3a45>\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, review)\u001b[0m\n\u001b[0;32m    205\u001b[0m                 \u001b[0munique_indices\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword2index\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32min\u001b[0m \u001b[0munique_indices\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 207\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer_1\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights_0_1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    208\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    209\u001b[0m         \u001b[1;31m# Output layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (1,5) (6,) (1,5) "
     ]
    }
   ],
   "source": [
    "mlp.test(reviews,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
